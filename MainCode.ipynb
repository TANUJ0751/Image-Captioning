{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca286fde-5e03-47be-8d93-8ec7d48cfb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fc6f42c-bb75-4de1-9666-fe4ebfd5e378",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-05 09:45:42.977314: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1736070343.094832    2442 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1736070343.130658    2442 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-05 09:45:43.416185: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow.keras.applications.vgg16 import VGG16,preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical,plot_model\n",
    "from tensorflow.keras.layers import Input,Dense,LSTM,Embedding,Dropout,add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dd012f8-0529-4d7f-b3ac-d63bd8110ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1736070349.301457    2442 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2248 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ fc1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │   <span style=\"color: #00af00; text-decoration-color: #00af00\">102,764,544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ fc2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">16,781,312</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m1,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv3 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv3 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv3 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ fc1 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │   \u001b[38;5;34m102,764,544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ fc2 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │    \u001b[38;5;34m16,781,312\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,260,544</span> (512.16 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m134,260,544\u001b[0m (512.16 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,260,544</span> (512.16 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m134,260,544\u001b[0m (512.16 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "###EXtract Image Featurs\n",
    "#load VGG16 model\n",
    "model=VGG16()\n",
    "#restructure Model\n",
    "model=Model(inputs=model.inputs,outputs=model.layers[-2].output)\n",
    "#summarize\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "669c92b9-e8e0-4e84-b1c5-21e993a14ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for img_name in tqdm(os.listdir(directory)):\\n    #load image form file\\n    \\n    img_path=directory+'/'+img_name\\n    image=load_img(img_path,target_size=(224,224))\\n    #image.show()\\n    \\n    \\n    #convert image to numpy array\\n    image=img_to_array(image)\\n    #reshape data for model\\n    image=image.reshape((1,image.shape[0],image.shape[1], image.shape[2]))\\n    #preprocess image for VGG16\\n    image=preprocess_input(image)\\n    #extract features\\n    feature=model.predict(image,verbose=0)\\n    #get image ID\\n    image_id=img_name.split('.')[0]\\n    \\n    \\n    features[image_id]=feature\\n    \\n    \""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extract Features from Image\n",
    "features={}\n",
    "directory='./Images'\n",
    "\n",
    "'''for img_name in tqdm(os.listdir(directory)):\n",
    "    #load image form file\n",
    "    \n",
    "    img_path=directory+'/'+img_name\n",
    "    image=load_img(img_path,target_size=(224,224))\n",
    "    #image.show()\n",
    "    \n",
    "    \n",
    "    #convert image to numpy array\n",
    "    image=img_to_array(image)\n",
    "    #reshape data for model\n",
    "    image=image.reshape((1,image.shape[0],image.shape[1], image.shape[2]))\n",
    "    #preprocess image for VGG16\n",
    "    image=preprocess_input(image)\n",
    "    #extract features\n",
    "    feature=model.predict(image,verbose=0)\n",
    "    #get image ID\n",
    "    image_id=img_name.split('.')[0]\n",
    "    \n",
    "    \n",
    "    features[image_id]=feature\n",
    "    \n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "936fd6b8-1efe-43e1-8fa9-387651af7be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"data = features\\n# Save the data to a pickle file\\nwith open('features.pkl', 'wb') as f:  # 'wb' ensures binary write mode\\n    pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)  # Use highest protocol for compatibility\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#store features in pickle\n",
    "'''data = features\n",
    "# Save the data to a pickle file\n",
    "with open('features.pkl', 'wb') as f:  # 'wb' ensures binary write mode\n",
    "    pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)  # Use highest protocol for compatibility'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b30fd6d1-9b44-4860-8448-e7c318eb8655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "#load features from pickle\n",
    "try:\n",
    "    with open('./vars/features.pkl', 'rb') as f:\n",
    "        features = pickle.load(f)\n",
    "        print(\"Features loaded successfully.\")\n",
    "except EOFError:\n",
    "    print(\"The file is empty or corrupted. Please regenerate the pickle file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "870ebfc0-2d69-49dc-935a-4df4ff0e34f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load captions data\n",
    "with open('./vars/captions.txt','r') as f:\n",
    "    next(f)\n",
    "    captions_doc=f.read()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59780f51-9d6e-4ba8-bd0b-8cfcd2045fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#captions_doc\n",
    "#features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "935c422c-1a27-4620-8c55-0abe07c7499e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe76bf8177349b6b8f1e1e8d042c30e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40456 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#create mapping of image to captions\n",
    "mapping={}\n",
    "#process lines\n",
    "for line in tqdm(captions_doc.split('\\n')):\n",
    "    #split the line by comma\n",
    "    tokens=line.split(',')\n",
    "    if len(line)<2:\n",
    "        continue\n",
    "    image_id,caption=tokens[0],tokens[1:]\n",
    "    #remove extension from image id\n",
    "    image_id=image_id.split('.')[0]\n",
    "    #convert caption list to string\n",
    "    caption=\" \".join(caption)\n",
    "    #create list if needed\n",
    "    if image_id not in mapping:\n",
    "        mapping[image_id]=[]\n",
    "    mapping[image_id].append(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2eb26876-dd18-4602-bebd-62e28958174a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8091"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72a8cf2b-2234-4f61-a4d7-790e06c6930a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess Text Data\n",
    "def clean(mapping):\n",
    "    for key,captions in mapping.items():\n",
    "        for i in range(len(captions)):\n",
    "            #take one caption at a time\n",
    "            caption=captions[i]\n",
    "            #preprocessing steps\n",
    "            caption=caption.lower()#convert to lower case\n",
    "            caption=caption.replace('[^A-Za-z]','')#removing special characters and digits\n",
    "            caption=caption.replace(r'\\s+',' ')#removing multiple spaces\n",
    "            \n",
    "            #add start and end tags\n",
    "            caption='startseq '+\" \".join([word for word in caption.split() if len(word)>1])+' endseq'\n",
    "            captions[i]=caption\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbbc1ea2-b9cf-4c72-a940-bd20e992bdf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A child in a pink dress is climbing up a set of stairs in an entry way .',\n",
       " 'A girl going into a wooden building .',\n",
       " 'A little girl climbing into a wooden playhouse .',\n",
       " 'A little girl climbing the stairs to her playhouse .',\n",
       " 'A little girl in a pink dress going into a wooden cabin .']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#before preprocess \n",
    "mapping['1000268201_693b08cb0e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8c368dd-cfa6-47dc-b096-40c41bbc2531",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess the text\n",
    "clean(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5fb4d71-c3c2-48d6-807e-b9082e2d1848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['startseq child in pink dress is climbing up set of stairs in an entry way endseq',\n",
       " 'startseq girl going into wooden building endseq',\n",
       " 'startseq little girl climbing into wooden playhouse endseq',\n",
       " 'startseq little girl climbing the stairs to her playhouse endseq',\n",
       " 'startseq little girl in pink dress going into wooden cabin endseq']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#after Preprocess\n",
    "mapping['1000268201_693b08cb0e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11180823-a6ce-41ab-9059-a4f49ab2ac67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./vars/Mapping.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(mapping,\"./vars/Mapping.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6ea2d8d-917d-47a4-871e-3387831a8a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_captions=[]\n",
    "for key in mapping:\n",
    "    for caption in mapping[key]:\n",
    "        all_captions.append(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa81d142-4e38-4a5e-87c9-2ab1571c549e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40455"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adc99594-3d40-4423-a39c-4bcb2eb7cc29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['startseq child in pink dress is climbing up set of stairs in an entry way endseq',\n",
       " 'startseq girl going into wooden building endseq',\n",
       " 'startseq little girl climbing into wooden playhouse endseq',\n",
       " 'startseq little girl climbing the stairs to her playhouse endseq',\n",
       " 'startseq little girl in pink dress going into wooden cabin endseq',\n",
       " 'startseq black dog and spotted dog are fighting endseq',\n",
       " 'startseq black dog and tri-colored dog playing with each other on the road endseq',\n",
       " 'startseq black dog and white dog with brown spots are staring at each other in the street endseq',\n",
       " 'startseq two dogs of different breeds looking at each other on the road endseq',\n",
       " 'startseq two dogs on pavement moving toward each other endseq']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_captions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a81bd318-86d8-4970-81f6-1a2a382e42dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8485"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenize the text\n",
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts(all_captions)\n",
    "dump(tokenizer,'./vars/Tokenizer.joblib')\n",
    "vocab_size=len(tokenizer.word_index)+1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24d4c289-9c95-4f21-8ebc-f457692777ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get max length of the caption available\n",
    "max_len=max(len(caption.split()) for caption in all_captions)\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef7510ce-48a3-41a7-b4a6-46ca29ea0575",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test Split\n",
    "image_ids=list(mapping.keys())\n",
    "split=int(len(image_ids)*0.90)\n",
    "train=image_ids[:split]\n",
    "test=image_ids[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c33494bc-4614-46af-aba8-90796496ad8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data generator to get data in batch (avoids session crash)\n",
    "def data_generator(data_keys, mapping, features, tokenizer, max_length, vocab_size, batch_size):\n",
    "    # loop over images\n",
    "    X1, X2, y = list(), list(), list()\n",
    "    n = 0\n",
    "    while 1:\n",
    "        for key in data_keys:\n",
    "            n += 1\n",
    "            captions = mapping[key]\n",
    "            # process each caption\n",
    "            for caption in captions:\n",
    "                # encode the sequence\n",
    "                seq = tokenizer.texts_to_sequences([caption])[0]\n",
    "                # split the sequence into X, y pairs\n",
    "                for i in range(1, len(seq)):\n",
    "                    # split into input and output pairs\n",
    "                    in_seq, out_seq = seq[:i], seq[i]\n",
    "                    # pad input sequence\n",
    "                    in_seq = pad_sequences([in_seq], maxlen=max_length, padding='post')[0]\n",
    "                    # encode output sequence\n",
    "                    out_seq = to_categorical([out_seq], \tnum_classes=vocab_size)[0]\n",
    "                    # store the sequences\n",
    "                    X1.append(features[key][0])\n",
    "                    X2.append(in_seq)\n",
    "                    y.append(out_seq)\n",
    "            if n == batch_size:\n",
    "                X1, X2, y = np.array(X1), np.array(X2), np.array(y)\n",
    "                yield {'image': X1, 'text': X2}, y\n",
    "                X1, X2, y = list(), list(), list()\n",
    "                n = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "010df596-bf9d-4b2c-9499-dfe8e509dc78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'inputs1 = Input(shape=(4096,), name=\"image\")\\nfe1 = Dropout(0.4)(inputs1)\\nfe2 = Dense(256, activation=\\'relu\\')(fe1)\\n# sequence feature layers\\ninputs2 = Input(shape=(max_len,), name=\"text\")\\nse1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\\nse2 = Dropout(0.4)(se1)\\nse3 = LSTM(256)(se2)\\n\\n# decoder model\\ndecoder1 = add([fe2, se3])\\ndecoder2 = Dense(256, activation=\\'relu\\')(decoder1)\\noutputs = Dense(vocab_size, activation=\\'softmax\\')(decoder2)\\n\\nmodel = Model(inputs=[inputs1, inputs2], outputs=outputs)\\nmodel.compile(loss=\\'categorical_crossentropy\\', optimizer=\\'adam\\')\\n\\n# plot the model\\nplot_model(model, show_shapes=True)'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoder model\n",
    "# image feature layers\n",
    "'''inputs1 = Input(shape=(4096,), name=\"image\")\n",
    "fe1 = Dropout(0.4)(inputs1)\n",
    "fe2 = Dense(256, activation='relu')(fe1)\n",
    "# sequence feature layers\n",
    "inputs2 = Input(shape=(max_len,), name=\"text\")\n",
    "se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
    "se2 = Dropout(0.4)(se1)\n",
    "se3 = LSTM(256)(se2)\n",
    "\n",
    "# decoder model\n",
    "decoder1 = add([fe2, se3])\n",
    "decoder2 = Dense(256, activation='relu')(decoder1)\n",
    "outputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
    "\n",
    "model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# plot the model\n",
    "plot_model(model, show_shapes=True)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3804496b-fe2c-439b-af06-8b05e4ec5028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "524f7283-8d89-42d2-8efb-f1c914b37939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1736070357.975088    2863 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 107ms/step - loss: 1.4095\n",
      "epoch : 1\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 103ms/step - loss: 1.4088\n",
      "epoch : 2\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 113ms/step - loss: 1.4075\n",
      "epoch : 3\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 105ms/step - loss: 1.3999\n",
      "epoch : 4\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 106ms/step - loss: 1.3976\n",
      "epoch : 5\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 115ms/step - loss: 1.3923\n",
      "epoch : 6\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 108ms/step - loss: 1.3871\n",
      "epoch : 7\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 110ms/step - loss: 1.3846\n",
      "epoch : 8\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 119ms/step - loss: 1.3860\n",
      "epoch : 9\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 120ms/step - loss: 1.3806\n",
      "epoch : 10\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 115ms/step - loss: 1.3793\n",
      "epoch : 11\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 108ms/step - loss: 1.3764\n",
      "epoch : 12\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 111ms/step - loss: 1.3743\n",
      "epoch : 13\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 106ms/step - loss: 1.3687\n",
      "epoch : 14\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 133ms/step - loss: 1.3664\n",
      "epoch : 15\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 140ms/step - loss: 1.3675\n",
      "epoch : 16\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 137ms/step - loss: 1.3602\n",
      "epoch : 17\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 128ms/step - loss: 1.3608\n",
      "epoch : 18\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 117ms/step - loss: 1.3551\n",
      "epoch : 19\n",
      "\u001b[1m227/227\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 123ms/step - loss: 1.3552\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "steps = len(train) // batch_size\n",
    "model=load_model(\"./model/best_model_120_epochs.keras\")\n",
    "for i in range(epochs):\n",
    "    # create data generator\n",
    "    generator = data_generator(train, mapping, features, tokenizer, max_len, vocab_size, batch_size)\n",
    "    print(\"epoch : %d\" %i)\n",
    "    # fit for one epoch\n",
    "    model.fit(generator, epochs=1, steps_per_epoch=steps, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3aa79bc9-ce9b-4e7d-88ed-99d2ea30949c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#os.makedirs(\"model\", exist_ok=True)\n",
    "model.save(\"./model/best_model_150_epochs.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "528eb0af-ad72-4848-be70-27ee8e5ea46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate Captions for Image\n",
    "def idx_to_word(integer,tokenizer):\n",
    "    for word,index in tokenizer.word_index.items():\n",
    "        if index == integer: \n",
    "            return word\n",
    "    return none\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e62d2b2d-3dbd-4ef3-bf5a-d055610e279f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate caption for an image\n",
    "def predict_caption(model,image,tokenizer,max_length):\n",
    "    #add start tag for generation\n",
    "    in_text='startseq'\n",
    "    #iterate over maxlength of sequence\n",
    "    for i in range(max_length):\n",
    "        #incode input sequence\n",
    "        sequence=tokenizer.texts_to_sequences([in_text])[0]\n",
    "        #pad the sequence\n",
    "        sequence=pad_sequences([sequence],max_length)\n",
    "        #predict next word\n",
    "        yhat=model.predict([image,sequence],verbose=0)\n",
    "        #convert index with high probability\n",
    "        yhat=np.argmax(yhat)\n",
    "        #convert index to word\n",
    "        word=idx_to_word(yhat,tokenizer)\n",
    "        #stop if word not found\n",
    "        if word is None:\n",
    "            break\n",
    "        #append word as input for generation next word\n",
    "        in_text +=\" \"+word\n",
    "        #stop if we reach end tag\n",
    "        if word =='endseq':\n",
    "            break\n",
    "    return in_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c337ff3-9275-41e7-a875-61bbcc03d27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from nltk.translate.bleu_score import corpus_bleu\\n#validate with test data\\nactual,predicted=[],[]\\nfor key in tqdm(test):\\n    #get actudal caption\\n    captions=mapping[key]\\n    #predict the caption for image\\n    y_pred=predict_caption(model,features[key],tokenizer,max_len)\\n    #split into words\\n    actual_captions=[caption.split() for caption in captions]\\n    y_pred=y_pred.split()\\n    actual.append(actual_captions)\\n    predicted.append(y_pred)\\n#Calculate BLEU Score\\nprint(\"Corpus will be started\")\\nprint(\"BLEU-1: %f\" %corpus_bleu(actual,predicted,weights=(1.0,0,0,0)))\\nprint(\"BLEU-1: %f\" %corpus_bleu(actual,predicted,weights=(0.5,0.5,0,0)))'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "#validate with test data\n",
    "actual,predicted=[],[]\n",
    "for key in tqdm(test):\n",
    "    #get actudal caption\n",
    "    captions=mapping[key]\n",
    "    #predict the caption for image\n",
    "    y_pred=predict_caption(model,features[key],tokenizer,max_len)\n",
    "    #split into words\n",
    "    actual_captions=[caption.split() for caption in captions]\n",
    "    y_pred=y_pred.split()\n",
    "    actual.append(actual_captions)\n",
    "    predicted.append(y_pred)\n",
    "#Calculate BLEU Score\n",
    "print(\"Corpus will be started\")\n",
    "print(\"BLEU-1: %f\" %corpus_bleu(actual,predicted,weights=(1.0,0,0,0)))\n",
    "print(\"BLEU-1: %f\" %corpus_bleu(actual,predicted,weights=(0.5,0.5,0,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f696a5f7-144c-4e9f-bf71-08aebebf2c09",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "model3=tf.keras.models.load_model(\"./model/best_model_90_epochs.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "776cb0d1-e282-45f8-ba34-1bd21e15bd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Visualize results\\\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "def generate_caption(image_name,model):\n",
    "    #load Image\n",
    "    #image_name=\"1002674143_1b742ab4b8.jpg\"\n",
    "    image_id=image_name.split('.')[0]\n",
    "    image_path=os.path.join(\"Images\",image_name)\n",
    "    image=Image.open(image_path)\n",
    "    \n",
    "    captions=mapping[image_id]\n",
    "    print(\"---------------------------Original Caption--------------------------\")\n",
    "    for caption in captions:\n",
    "        print(caption)\n",
    "    \n",
    "    #predict the caption\n",
    "    y_pred=predict_caption(model,features[image_id],tokenizer,max_len)\n",
    "    \n",
    "    print(\"--------------------------Predicted Caption----------------\")\n",
    "    print(y_pred)\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1a88421-c7ec-4cf5-bd61-3674e2dd0775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------Original Caption--------------------------\n",
      "startseq three girls do back flips and cartwheels in the surf endseq\n",
      "startseq three girls do handstands at the beach endseq\n",
      "startseq three girls doing back flips on the beach endseq\n",
      "startseq three little girls cartwheel in the ocean endseq\n",
      "startseq three young girls playing on the beach endseq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-05 09:54:56.275000: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: INVALID_ARGUMENT: assertion failed: [You are passing a RNN mask that does not correspond to right-padded sequences, while using cuDNN, which is not supported. With cuDNN, RNN masks can only be used for right-padding, e.g. `[[True, True, False, False]]` would be a valid mask, but any mask that isn\\'t just contiguous `True`\\'s on the left and contiguous `False`\\'s on the right would be invalid. You can pass `use_cudnn=False` to your RNN layer to stop using cuDNN (this may be slower).]\n",
      "\t [[{{node functional_1_1/lstm_1/Assert/Assert}}]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node functional_1_1/lstm_1/Assert/Assert defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 701, in start\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/asyncio/base_events.py\", line 1986, in _run_once\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_2442/2716764408.py\", line 1, in <module>\n\n  File \"/tmp/ipykernel_2442/1558396786.py\", line 17, in generate_caption\n\n  File \"/tmp/ipykernel_2442/3359475186.py\", line 12, in predict_caption\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 559, in predict\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 256, in one_step_on_data_distributed\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 246, in one_step_on_data\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 101, in predict_step\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/layers/layer.py\", line 899, in __call__\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/models/functional.py\", line 182, in call\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/ops/function.py\", line 171, in _run_through_graph\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/models/functional.py\", line 632, in call\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/layers/layer.py\", line 899, in __call__\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/layers/rnn/lstm.py\", line 570, in call\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py\", line 402, in call\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/layers/rnn/lstm.py\", line 537, in inner_loop\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/backend/tensorflow/rnn.py\", line 841, in lstm\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/backend/tensorflow/rnn.py\", line 874, in _cudnn_lstm\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/backend/tensorflow/rnn.py\", line 557, in _assert_valid_mask\n\nassertion failed: [You are passing a RNN mask that does not correspond to right-padded sequences, while using cuDNN, which is not supported. With cuDNN, RNN masks can only be used for right-padding, e.g. `[[True, True, False, False]]` would be a valid mask, but any mask that isn\\'t just contiguous `True`\\'s on the left and contiguous `False`\\'s on the right would be invalid. You can pass `use_cudnn=False` to your RNN layer to stop using cuDNN (this may be slower).]\n\t [[{{node functional_1_1/lstm_1/Assert/Assert}}]] [Op:__inference_one_step_on_data_distributed_43164]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m generate_caption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3747543364_bf5b548527.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m,model3)\n",
      "Cell \u001b[0;32mIn[30], line 17\u001b[0m, in \u001b[0;36mgenerate_caption\u001b[0;34m(image_name, model)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(caption)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#predict the caption\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m y_pred\u001b[38;5;241m=\u001b[39mpredict_caption(model,features[image_id],tokenizer,max_len)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--------------------------Predicted Caption----------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_pred)\n",
      "Cell \u001b[0;32mIn[27], line 12\u001b[0m, in \u001b[0;36mpredict_caption\u001b[0;34m(model, image, tokenizer, max_length)\u001b[0m\n\u001b[1;32m     10\u001b[0m sequence\u001b[38;5;241m=\u001b[39mpad_sequences([sequence],max_length)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#predict next word\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m yhat\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict([image,sequence],verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#convert index with high probability\u001b[39;00m\n\u001b[1;32m     14\u001b[0m yhat\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39margmax(yhat)\n",
      "File \u001b[0;32m~/anacondaWSL/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anacondaWSL/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node functional_1_1/lstm_1/Assert/Assert defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 701, in start\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/asyncio/base_events.py\", line 1986, in _run_once\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_2442/2716764408.py\", line 1, in <module>\n\n  File \"/tmp/ipykernel_2442/1558396786.py\", line 17, in generate_caption\n\n  File \"/tmp/ipykernel_2442/3359475186.py\", line 12, in predict_caption\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 559, in predict\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 256, in one_step_on_data_distributed\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 246, in one_step_on_data\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 101, in predict_step\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/layers/layer.py\", line 899, in __call__\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/models/functional.py\", line 182, in call\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/ops/function.py\", line 171, in _run_through_graph\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/models/functional.py\", line 632, in call\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/layers/layer.py\", line 899, in __call__\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/ops/operation.py\", line 46, in __call__\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/layers/rnn/lstm.py\", line 570, in call\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py\", line 402, in call\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/layers/rnn/lstm.py\", line 537, in inner_loop\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/backend/tensorflow/rnn.py\", line 841, in lstm\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/backend/tensorflow/rnn.py\", line 874, in _cudnn_lstm\n\n  File \"/home/tanuj/anacondaWSL/lib/python3.12/site-packages/keras/src/backend/tensorflow/rnn.py\", line 557, in _assert_valid_mask\n\nassertion failed: [You are passing a RNN mask that does not correspond to right-padded sequences, while using cuDNN, which is not supported. With cuDNN, RNN masks can only be used for right-padding, e.g. `[[True, True, False, False]]` would be a valid mask, but any mask that isn\\'t just contiguous `True`\\'s on the left and contiguous `False`\\'s on the right would be invalid. You can pass `use_cudnn=False` to your RNN layer to stop using cuDNN (this may be slower).]\n\t [[{{node functional_1_1/lstm_1/Assert/Assert}}]] [Op:__inference_one_step_on_data_distributed_43164]"
     ]
    }
   ],
   "source": [
    "generate_caption(\"3747543364_bf5b548527.jpg\",model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afaa51f-ff47-4715-be85-7dbab72d369a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
